<!DOCTYPE html>
    <html>
    <head>
        <meta charset="UTF-8">
        <title>Perf tool</title>
        <style>
/* From extension vscode.github */
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

.vscode-dark img[src$=\#gh-light-mode-only],
.vscode-light img[src$=\#gh-dark-mode-only] {
	display: none;
}

</style>
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css">
<link href="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css" rel="stylesheet" type="text/css">
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Microsoft/vscode/extensions/markdown-language-features/media/markdown.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Microsoft/vscode/extensions/markdown-language-features/media/highlight.css">
<style>
            body {
                font-family: -apple-system, BlinkMacSystemFont, 'Segoe WPC', 'Segoe UI', system-ui, 'Ubuntu', 'Droid Sans', sans-serif;
                font-size: 14px;
                line-height: 1.6;
            }
        </style>
        <style>
.task-list-item {
    list-style-type: none;
}

.task-list-item-checkbox {
    margin-left: -20px;
    vertical-align: middle;
    pointer-events: none;
}
</style>
        <style>
#button {
    display: inline-block;
    background-color: #FF9800;
    width: 50px;
    height: 50px;
    text-align: center;
    border-radius: 4px;
    position: fixed;
    bottom: 30px;
    right: 30px;
    transition: background-color .3s, 
      opacity .5s, visibility .5s;
    opacity: 0;
    /*visibility: hidden;*/
    z-index: 1000;
}
#button::after {
    content: "\f077";
    font-family: FontAwesome;
    font-weight: normal;
    font-style: normal;
    font-size: 2em;
    line-height: 50px;
    color: #fff;
}
#button:hover {
    cursor: pointer;
    background-color: #333;
}
#button:active {
    background-color: #555;
}
#button.show {
    opacity: 1;
    visibility: visible;
}

#btn-back-to-top {
    position: fixed;
    bottom: 20px;
    right: 20px;
    display: none;
  }

  .to-top {
    background: white;
    position: fixed;
    bottom: 16px;
    right:32px;
    width:50px;
    height:50px;
    border-radius: 50%;
    border-color: white;
    display: flex;
    align-items: center;
    justify-content: center;
    font-size:32px;
    color:#1f1f1f;
    text-decoration: none;
    opacity: 0.5;
    pointer-events: auto;
    transition: all .4s;
    transform: rotate(270deg);
  }
  
</style>
    </head>
    <body class="vscode-body vscode-light">
        <!-- title: Perf tool -->
<h1>Perf and performance utility</h1>
<p><a href="#" class="to-top">➤</i></a></p>
<ul>
<li><a href="#overview">Overview</a>
<ul>
<li><a href="#why-perf">why <code>perf</code></a></li>
<li><a href="#perf-has-couple-modes"><code>perf</code> has couple modes</a></li>
<li><a href="#perf-basic-workflow"><code>perf</code> basic workflow</a></li>
</ul>
</li>
<li><a href="#commands">Commands</a>
<ul>
<li><a href="#perf-stat"><code>perf stat</code></a></li>
<li><a href="#perf-record"><code>perf record</code></a></li>
<li><a href="#perf-report"><code>perf report</code></a></li>
<li><a href="#perf-script"><code>perf script</code></a></li>
<li><a href="#perf-sched"><code>perf sched</code></a></li>
</ul>
</li>
<li><a href="#stats">Stats</a>
<ul>
<li><a href="#retired-vs-executed-instruction">Retired vs. Executed Instruction</a></li>
<li><a href="#cpu-utilization">CPU Utilization</a></li>
<li><a href="#cpi--ipc">CPI &amp; IPC</a></li>
<li><a href="#uops-micro-ops">UOPs (micro-ops)</a></li>
<li><a href="#core-vs-reference-cycles">Core vs. Reference Cycles</a></li>
<li><a href="#cache-miss">Cache miss</a></li>
<li><a href="#mispredicted-branch">Mispredicted branch</a></li>
</ul>
</li>
</ul>
<h1 id="overview">Overview</h1>
<h2 id="why-perf">why <code>perf</code></h2>
<ul>
<li>Avaiable: linux, open source</li>
<li>Low overhead: tunable sampling, ring buffers</li>
<li>Accurate: applicaiton-based samplers dont know whats really running: eg, Java and epoll</li>
<li>No bind spots
<ul>
<li>see user, library, kernel with CPU sampling</li>
<li>with some work: hardirqs and SMI as well</li>
</ul>
</li>
<li>No sampling skew
<ul>
<li>it takes sample any time it wants. Unlike java JVM profiler has to wait at safety point to sample, causing skews.</li>
</ul>
</li>
</ul>
<h2 id="perf-has-couple-modes"><code>perf</code> has couple modes</h2>
<ol>
<li>Gather statistics for application or system: <code>perf stat</code></li>
<li>Record a profile and analyze it later: <code>perf record + perf report</code></li>
<li>Real-time function-wise analysis: <code>perf top</code></li>
<li>Trace application or system: <code>perf trace</code></li>
</ol>
<h2 id="perf-basic-workflow"><code>perf</code> basic workflow</h2>
<ol>
<li>list -&gt; find events</li>
<li>stat -&gt; count them</li>
<li>record -&gt; write event data to file</li>
<li>report -&gt; browse summary</li>
<li>script -&gt; event dump for post processing</li>
</ol>
<p><img src="images/2022-05-10-09-46-37.png" alt=""></p>
<br>
<br>
<h1 id="commands">Commands</h1>
<h2 id="perf-stat"><code>perf stat</code></h2>
<p>For stats counting (perf stat), it uses several sources</p>
<ul>
<li>Some events are pure <strong>kernel counters</strong>, in this case they are called <em>software events</em>.
<ul>
<li>Examples include: context-switches, major/minor-faults.</li>
</ul>
</li>
<li>Another source of events is the processor’s Performance Monitoring Unit (<strong>PMU</strong>). It provides a list of events to measure micro-architectural hardware events. They vary with processor type and model.
<ul>
<li>Examples: the number of cycles, instructions retired, L1 cache misses and so on.</li>
</ul>
</li>
<li>It also provides a small set of common hardware events moniters, On each processor, those events get mapped onto actual events provided by the CPU. These are mainly <strong>hardware cache events.</strong>
<ul>
<li>Examples: L1 d/icahce loads/stores/miss, di/TLB loads/misses/prefetches, LLC loads/stores/misses</li>
</ul>
</li>
<li><strong>Raw hardware event</strong> codes are alphanumeric encodings of the hardware events. These are mostly needed when the hardware is newer than the kernel and the user needs to enable events that are new for that hardware. Users will rarely, if ever, need to use raw event codes.</li>
<li><strong>tracepoint event</strong>: these are implemented by the kernel ftrace infrastructure. Those are only available with the 2.6.3x and newer kernels. These are triggered when that section of code is executed by the kernel.
<ul>
<li>Examples: mainly scheduler stats (how long waits), system call stats</li>
</ul>
</li>
<li><strong>User-level statically-defined tracing (USDT)</strong> is the user-space version of tracepoints.</li>
</ul>
<p><code>perf</code> provides mappings for commonly used performance counters. List of available mapping names can be viewed with <code>perf list</code></p>
<p><code>perf</code> doesn’t provide mappings for all performance counters for every CPU architecture. If the PMC you are looking for doesn’t have a mapping, it can be collected with the following syntax:</p>
<pre><code>$ perf stat -e cpu/event=0xc4,umask=0x0,name=BR_INST_RETIRED.ALL_BRANCHES/ -- ./a.exe
</code></pre>
<p>tracepoint （以下简称&quot;tp&quot;）是“埋”在内核源码中的一些原生 hook（如果是埋在用户态的代码中则是 USDT），在这个 hook 点位上你可以提取一些信息，由于是在固定的位置，且在编译阶段就已确定，因此被称为「静态追踪点」。而像 systemtap 用的 kprobe/uprobe，可以在几乎任一指令处打点，这种“野生”的 hook 就属于「动态追踪点」</p>
<ul>
<li>一个 tp 开启的时候（on），每次代码执行到这个点位，都可以采集当时的 context 信息，而当它不被使用的时候（off），从时间层面，有一些分支判断的开销，从空间层面，存在一些由增加的指令/数据结构所带来的开销。其原理和同为静态追踪的 ftrace 很相似，区别是 tp 的 hook 点通常位于一个函数的中间部分，而传统的 ftrace 位于一个函数的开头（不过现在的 ftrace 功能已经扩展了）。</li>
<li>按理「静态追踪点」可以完成的事，动态追踪都可以完成，前者似乎是后者的一个子集，那静态追踪还有什么存在的价值？内核 API 是经常变动的，相对来说，tracepoint 会尽量保持 API 的稳定，并且其配套的文档描述也更完善。</li>
</ul>
<table>
<thead>
<tr>
<th></th>
<th>静态</th>
<th>动态</th>
</tr>
</thead>
<tbody>
<tr>
<td>用户态</td>
<td>USDT</td>
<td>uprobe</td>
</tr>
<tr>
<td>内核态</td>
<td>tracepoint</td>
<td>kprobe</td>
</tr>
</tbody>
</table>
<p><code>perf stat</code> is efficient: it counts software events in kernel context and hardware events using PMC registers.</p>
<p>The stat subcommand supports many options, including:</p>
<ul>
<li><code>-a</code>: Record across all CPUs (this became the default in Linux 4.11)</li>
<li><code>-e event</code>: Record this event(s)</li>
<li><code>--filter filter</code>: Set a Boolean filter expression for an event</li>
<li><code>-p PID</code>: Record this PID only</li>
<li><code>-t TID</code>: Record this thread ID only</li>
<li><code>-G cgroup</code>: Record this cgroup only (used for containers)</li>
<li><code>-A</code>: Show per-CPU counts</li>
<li><code>-I</code> interval_ms: Print output every interval (milliseconds)</li>
<li><code>-v</code>: Show verbose messages; <code>-vv</code> for more messages</li>
</ul>
<pre><code class="language-bash">perf list         <span class="hljs-comment"># print available metrics</span>
perf list block   <span class="hljs-comment"># List events with names containing the string “block”:</span>

perf <span class="hljs-built_in">stat</span> cmd     <span class="hljs-comment"># print default metrics</span>
perf <span class="hljs-built_in">stat</span> -d cmd  <span class="hljs-comment"># &quot;-d&quot; short for &quot;--detailed&quot;, print more detailed stats. Can be specified multiple times each with more detailed stats</span>
perf <span class="hljs-built_in">stat</span> -p PID  <span class="hljs-comment"># for the specified PID, until Ctrl-C:</span>

<span class="hljs-comment"># &quot;-a&quot; short for &quot;--all-cpus&quot;. Performance counter statistics for the entire system, for 10 seconds:</span>
perf <span class="hljs-built_in">stat</span> -a --<span class="hljs-built_in">sleep</span> 10

<span class="hljs-comment">#print selected metrics</span>
perf <span class="hljs-built_in">stat</span> -e cycles,instructions,brances,branch-misses,cache-references,cache-misses ./cmd        

<span class="hljs-comment"># Various CPU level 1 data cache statistics for the specified command:</span>
perf <span class="hljs-built_in">stat</span> -e L1-dcache-loads,L1-dcache-load-misses,L1-dcache-stores ./cmd

<span class="hljs-comment"># Various CPU data TLB statistics for the specified command:</span>
perf <span class="hljs-built_in">stat</span> -e dTLB-loads,dTLB-load-misses,dTLB-prefetch-misses ./cmd

<span class="hljs-comment"># Various CPU last level cache statistics for the specified command:</span>
perf <span class="hljs-built_in">stat</span> -e LLC-loads,LLC-load-misses,LLC-stores,LLC-prefetches ./cmd

<span class="hljs-comment"># Count scheduler events for the specified PID, for 10 seconds:</span>
perf <span class="hljs-built_in">stat</span> -e <span class="hljs-string">&#x27;sched:*&#x27;</span> -p PID <span class="hljs-built_in">sleep</span> 10

<span class="hljs-comment"># Count system calls by type for the specified PID:</span>
perf <span class="hljs-built_in">stat</span> -e <span class="hljs-string">&#x27;syscalls:sys_enter_*&#x27;</span> -p PID 
</code></pre>
<h2 id="perf-record"><code>perf record</code></h2>
<p>You must first collect the samples using <code>perf record</code>. This generates an output file called perf.data. That file can then be analyzed, possibly on another machine, using the <code>perf report</code> and perf annotate</p>
<p>it is non-invasive, low-overhead and profile the whole stack, including your app, libraries, system calls AND kernel with CPU. The average overhead of HW event-based sampling (EBS) is about 2% on a 1ms sampling interval.</p>
<p><strong><code>perf record</code></strong> is statistical profiling tool. Perf_events is based on event-based sampling. The period is expressed as the number of occurrences of an event, not the number of timer ticks. A sample is recorded when the sampling counter overflows, i.e., wraps from 2^64 back to 0. It uses program hardware performance event monitor unit (PMU) to overflow after some number of counts</p>
<ul>
<li>eg: with <code>-e cycles -c 1000000</code> , <code>perf</code> writes -1000000 to counter and enable counting cycles; It will archive one sample every 1 million instructions.</li>
<li>with <code>-F</code> or without freq/period argument it will autotune value</li>
<li>On every sample (or on interrupt from hardware PMU) <code>perf</code> will record current PC (EIP, instruction pointer,  i.e. where was the program when it was interrupted) and/or callstack; (<code>perf</code> has Interrupt Service Routine (ISR) for doing this)</li>
<li>When using <code>perf record</code> with PMCs, a default sample frequency (typically 4000) is used so that not every event is recorded.</li>
</ul>
<img src="images/2023-06-25-21-28-53.png" width="600">
<p><code>perf --help record</code></p>
<ul>
<li><code>-a</code>: Record across all CPUs (this became the default in Linux 4.11)</li>
<li><code>-e event</code>: Record this event(s)</li>
<li><code>--filter filter</code>: Set a Boolean filter expression for an event</li>
<li><code>-p PID</code>: Record this PID only</li>
<li><code>-t TID</code>: Record this thread ID only</li>
<li><code>-G cgroup</code>: Record this cgroup only (used for containers)</li>
<li><code>-g</code>: Record stack traces</li>
<li><code>-o file</code>: Set output file</li>
<li><code>-v</code>: Show verbose messages; -vv for more messages</li>
<li><code>--call-graph mode</code>: Record stack traces using a given method
<ul>
<li><code>--call-graph fp</code>: Selects frame pointer-based stack walking (the default).
<ul>
<li>Requires binary being built with <code>--fnoomit-frame-pointer</code>. Historically, frame pointer (RBP) was used for debugging since it allows us to get the call stack without popping all the arguments from the stack (stack unwinding). The frame pointer can tell the return address immediately. However, it consumes one register just for this purpose, so it was expensive.</li>
</ul>
</li>
<li><code>--call-graph dwarf</code>: Selects debuginfo-based stack walking, which requires debuginfo for the executable to be available.
<ul>
<li>Requires binary being built with DWARF debug information -g (-gline-tables-only).</li>
</ul>
</li>
<li><code>--call-graph lbr</code>: Selects Intel last branch record (LBR) stack walking, a processor-provided method (although it is typically limited to a stack depth of only 16 frames).</li>
</ul>
</li>
</ul>
<pre><code class="language-bash"><span class="hljs-comment"># Sample on-CPU functions for the specified command, at 99 Hertz (roughly 99 events per second):</span>
perf record -F 99 <span class="hljs-built_in">command</span>
</code></pre>
<h2 id="perf-report"><code>perf report</code></h2>
<p><em><code>*perf report</code></em>* will parse <code>perf.data</code> to get all PC recorded in it. It will count how many times each PC was sampled to build histogram [PC] -&gt; sample_count. Every PC will be associated with the exact function it belongs (<code>perf report</code> will parse memory map, as mmap events are recorded in <code>perf.data</code> too, open every binary used, find symbols table of every binary).</p>
<p><a href="https://man7.org/linux/man-pages/man1/perf-report.1.html">https://man7.org/linux/man-pages/man1/perf-report.1.html</a></p>
<p><code>perf --help report</code></p>
<ul>
<li><code>--tui</code>: Use the TUI interface (default)</li>
<li><code>--stdio</code>: Emit a text report</li>
<li><code>--header</code>: list data header</li>
<li><code>-i file</code>: Input file</li>
<li><code>-n</code>: Include a column for sample counts</li>
<li><code>-g options</code>: Modify call graph (stack trace) display options</li>
<li><code>-s or --sort= key1,key2</code>: sort the output by keys, check details in <code>--help</code></li>
<li><code>-g or --call-graph=</code>: display call chains, check details in <code>--help</code></li>
</ul>
<pre><code class="language-bash"><span class="hljs-comment"># Show perf.data in an ncurses browser (TUI) if possible:</span>
perf report

<span class="hljs-comment"># Show perf.data as a text report, with data coalesced and counts and percentages:</span>
perf report -n --stdio

<span class="hljs-comment"># List all perf.data events, with data header (recommended):</span>
perf script --header

<span class="hljs-comment"># List all perf.data events, with my recommended fields (needs record -a; Linux &lt; 4.1 used -f instead of -F)</span>
perf script --header -F <span class="hljs-built_in">comm</span>,pid,tid,cpu,time,event,ip,sym,dso

<span class="hljs-comment"># Generate a flame graph visualization (Linux 5.8+):</span>
perf script report flamegraph

<span class="hljs-comment"># Disassemble and annotate instructions with percentages (needs some debuginfo):</span>
perf annotate --stdio
</code></pre>
<h2 id="perf-script"><code>perf script</code></h2>
<p>The <code>perf script</code> subcommand by default prints each sample from perf.data, and is useful for spotting patterns over time that may be lost in a report summary.</p>
<h2 id="perf-sched"><code>perf sched</code></h2>
<p>The <code>sched</code> command records and reports scheduler statistics. Scheduler events are frequent, so this type of tracing incurs significant CPU and storage overhead. Be careful with this overhead, as it may perturb
production applications.</p>
<pre><code class="language-bash">perf <span class="hljs-built_in">sched</span> {record|latency|script|map|timehist}

<span class="hljs-comment">## example usage</span>
<span class="hljs-comment"># run record first</span>
$ perf <span class="hljs-built_in">sched</span> record -- <span class="hljs-built_in">sleep</span> 10
<span class="hljs-comment"># report the per-process scheduling latency</span>
$ perf <span class="hljs-built_in">sched</span> latency
<span class="hljs-comment"># perf sched also has map and timehist reports for displaying the scheduler profile in different ways.</span>
<span class="hljs-comment"># timehist report shows per-event details</span>
$ perf <span class="hljs-built_in">sched</span> timehist
</code></pre>
<br>
<h1 id="stats">Stats</h1>
<h2 id="retired-vs-executed-instruction">Retired vs. Executed Instruction</h2>
<p>for instructions executed speculatively, the CPU keeps their results without immediately committing their results. when it comes out that the speculation happens to be wrong, the CPU throws away all the changes done by speculative instructions and does not retire them. We can usually expect the number of executed instructions to be higher than the number of retired instructions.</p>
<p>There is a fixed performance counter (INST_RETIRED.ANY PMC) that collects the number of retired instructions.</p>
<pre><code>$ perf stat -e instructions ./a.exe
2173414 instructions # 0.80 insn per cycle
# or just simply do:
$ perf stat ./a.exe
</code></pre>
<h2 id="cpu-utilization">CPU Utilization</h2>
<p>the percentage of time the CPU was busy. Technically, a CPU is considered utilized when it is not running the kernel idle thread.</p>
<p>the CPU might be highly utilized even though it is stalled waiting on memory accesses. Or spin while waiting for resources
to proceed in multi-thread env.</p>
<pre><code> CPU Utilization = CPU_CLK_UNHALTED.REF_TSC PMC counts / TSC
</code></pre>
<p><code>perf</code> automatically calculates CPU utilization across all CPUs on the system:</p>
<pre><code>$ perf stat -- a.exe
0.634874 task-clock (msec) # 0.773 CPUs utilized
</code></pre>
<h2 id="cpi--ipc">CPI &amp; IPC</h2>
<ul>
<li>Cycles Per Instruction (CPI) - how many cycles it took to retire one instruction on average.
<ul>
<li><code>CPI = 1 / IPC</code></li>
</ul>
</li>
<li>Instructions Per Cycle (IPC) - how many instructions were retired per one cycle on average.
<ul>
<li><code>IPC = INST_RETIRED.ANY (retired instruction) / CPU_CLK_UNHALTED.THREAD</code></li>
</ul>
</li>
</ul>
<pre><code>$ perf stat -e cycles,instructions -- a.exe
2369632 cycles
1725916 instructions # 0,73 insn per cycle
# or just simply do:
$ perf stat ./a.exe
</code></pre>
<h2 id="uops-micro-ops">UOPs (micro-ops)</h2>
<pre><code>$ perf stat -e uops_issued.any,uops_executed.thread,uops_retired.all -- a.exe
2856278 uops_issued.any
2720241 uops_executed.thread
2557884 uops_retired.all # UOPS_RETIRED.ALL event is not available since Skylake. Use UOPS_RETIRED.RETIRE_SLOTS.
</code></pre>
<h2 id="core-vs-reference-cycles">Core vs. Reference Cycles</h2>
<p>The core clock cycles counter is counting clock cycles at the actual clock frequency that the CPU core is running at,
rather than the external clock (reference cycles). The core clock cycle counter is very useful when testing which version of a piece of code is fastest because you can avoid the problem that the clock frequency goes up and down.</p>
<pre><code># Metric &quot;cycles&quot; counts real CPU cycles, i.e., taking into account frequency scaling.
$ perf stat -e cycles,ref-cycles ./a.exe
43340884632 cycles # 3.97 GHz
37028245322 ref-cycles # 3.39 GHz
10,899462364 seconds time elapsed
</code></pre>
<h2 id="cache-miss">Cache miss</h2>
<p>Linux perf users can collect the number of L1-cache misses by running:</p>
<pre><code>$ perf stat -e mem_load_retired.fb_hit,mem_load_retired.l1_miss,mem_load_retired.l1_hit,mem_inst_retired.all_loads -- a.exe
29580 mem_load_retired.fb_hit
19036 mem_load_retired.l1_miss
497204 mem_load_retired.l1_hit
546230 mem_inst_retired.all_loads
</code></pre>
<p>further break down L1 data misses and analyze L2 cache behavior by running:</p>
<pre><code>$ perf stat -e mem_load_retired.l1_miss,mem_load_retired.l2_hit,mem_load_retired.l2_miss -- a.exe
19521 mem_load_retired.l1_miss
12360 mem_load_retired.l2_hit
7188 mem_load_retired.l2_miss
</code></pre>
<h2 id="mispredicted-branch">Mispredicted branch</h2>
<p>In <em>branch misprediction</em>, the CPU is required to undo all the speculative work that it has done recently. This typically involves a penalty between 10 and 20 clock cycles.</p>
<p>Linux perf users can check the number of branch mispredictions by running:</p>
<pre><code>$ perf stat -e branches,branch-misses -- a.exe
358209 branches
14026 branch-misses # 3,92% of all branches
# or simply do:
$ perf stat -- a.exe
</code></pre>
<br>
        <script async src="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js"></script>
        
    </body>
    </html>