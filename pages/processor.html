<!DOCTYPE html>
    <html>
    <head>
        <meta charset="UTF-8">
        <title>Processor</title>
        <style>
/* From extension vscode.github */
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

.vscode-dark img[src$=\#gh-light-mode-only],
.vscode-light img[src$=\#gh-dark-mode-only] {
	display: none;
}

</style>
        
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Microsoft/vscode/extensions/markdown-language-features/media/markdown.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Microsoft/vscode/extensions/markdown-language-features/media/highlight.css">
<style>
            body {
                font-family: -apple-system, BlinkMacSystemFont, 'Segoe WPC', 'Segoe UI', system-ui, 'Ubuntu', 'Droid Sans', sans-serif;
                font-size: 14px;
                line-height: 1.6;
            }
        </style>
        <style>
.task-list-item {
    list-style-type: none;
}

.task-list-item-checkbox {
    margin-left: -20px;
    vertical-align: middle;
    pointer-events: none;
}
</style>
        <style>
#button {
    display: inline-block;
    background-color: #FF9800;
    width: 50px;
    height: 50px;
    text-align: center;
    border-radius: 4px;
    position: fixed;
    bottom: 30px;
    right: 30px;
    transition: background-color .3s, 
      opacity .5s, visibility .5s;
    opacity: 0;
    /*visibility: hidden;*/
    z-index: 1000;
}
#button::after {
    content: "\f077";
    font-family: FontAwesome;
    font-weight: normal;
    font-style: normal;
    font-size: 2em;
    line-height: 50px;
    color: #fff;
}
#button:hover {
    cursor: pointer;
    background-color: #333;
}
#button:active {
    background-color: #555;
}
#button.show {
    opacity: 1;
    visibility: visible;
}

#btn-back-to-top {
    position: fixed;
    bottom: 20px;
    right: 20px;
    display: none;
  }

  .to-top {
    background: white;
    position: fixed;
    bottom: 16px;
    right:32px;
    width:50px;
    height:50px;
    border-radius: 50%;
    border-color: white;
    display: flex;
    align-items: center;
    justify-content: center;
    font-size:32px;
    color:#1f1f1f;
    text-decoration: none;
    opacity: 0.5;
    pointer-events: auto;
    transition: all .4s;
    transform: rotate(270deg);
  }
  
</style>
    </head>
    <body class="vscode-body vscode-light">
        <!-- title: Processor -->
<p><a href="#" class="to-top">➤</i></a></p>
<ul>
<li><a href="#cpu-pipeline">CPU pipeline</a>
<ul>
<li><a href="#cpu-front-end">CPU Front-End</a></li>
<li><a href="#cpu-back-end">CPU Back-End</a></li>
<li><a href="#the-pipeline-in-pm">The pipeline in PM</a></li>
</ul>
</li>
<li><a href="#cpu-execution-optimization">CPU execution optimization</a>
<ul>
<li><a href="#cpu-execution">CPU execution</a>
<ul>
<li><a href="#order-of-order-execution">Order of order execution</a></li>
<li><a href="#pipeline-hazards">Pipeline hazards</a></li>
<li><a href="#register-rename">Register rename</a></li>
<li><a href="#partial-register">Partial register</a></li>
</ul>
</li>
<li><a href="#micro-operations---uops">Micro-operations - uops</a>
<ul>
<li><a href="#macro-op-fusion">macro-op fusion</a></li>
</ul>
</li>
<li><a href="#instruction-fetch">Instruction fetch</a></li>
<li><a href="#speculative-execution">Speculative execution</a></li>
<li><a href="#branch-predication">Branch predication</a></li>
<li><a href="#optimize-jump-and-call">Optimize jump and call</a></li>
</ul>
</li>
</ul>
<h1 id="cpu-pipeline">CPU pipeline</h1>
<p>The pipeline in PPro, P2 and P3</p>
<p><img src="images/2022-01-24-22-25-38.png" alt=""></p>
<p>The main stages in the pipeline are:</p>
<ul>
<li>branch prediction,</li>
<li>instruction fetch (IF),</li>
<li>instruction decoding (ID),</li>
<li>register renaming,</li>
<li>reorder buffer read,</li>
<li>reservation station,</li>
<li>execution ports,</li>
<li>reorder buffer write-back (WB),</li>
<li>retirement.</li>
</ul>
<p><img src="images/2022-06-27-12-37-04.png" alt=""></p>
<h3 id="cpu-front-end">CPU Front-End</h3>
<p>The CPU Front-End consists of a number of data structures that serve the main goal to efficiently fetch and decode
instructions from memory. Its main purpose is to feed prepared instructions to the CPU Back-End, which is responsible for the actual execution of instructions.</p>
<ul>
<li>fetches 16 bytes per cycle of x86 instructions from the L1 I-cache.</li>
<li>The pre-decode and decode stages of the pipeline convert these complex x86 instructions into macro-ops
<ul>
<li>pre-decode stage determines and marks the boundaries of the variable instructions by inspecting the instruction.
<ul>
<li>In x86, the instruction length can range from 1-byte to 15-bytes instructions</li>
<li>This stage also identifies branch instructions.</li>
<li>This stage moves up to 6 uops to the instruction queue</li>
</ul>
</li>
</ul>
</li>
<li>The <strong>instruction queue</strong> also supports a <strong>macro-op fusion unit</strong> that detects that two uops can be fused into a single instruction to save bandwidth in the pipeline
<ul>
<li>Up to five pre-decoded instructions are sent from the instruction queue to the decoder every cycle.</li>
</ul>
</li>
<li><strong>uop cache</strong> (aka, Decoded Stream Buffer (DSB)) is a major performance boost feature
<ul>
<li>cache the macro-ops conversion in a separate structure (DSB) that works in parallel with the L1 I-cache.</li>
<li>During instruction fetch, the DSB is also checked to see if the macro-ops translations are already available in the DSB to avoid repeating the expensive pre-decode and decode operations for the 16 bytes bundle.</li>
</ul>
</li>
<li><strong>Microcode Sequencer (MSROM)</strong>:
<ul>
<li>Some very complicated instructions decoding: such instructions include HW operation support for string manipulation, encryption, synchronization, and others.</li>
<li>handle exceptional situations like branch misprediction (which requires pipeline flush)</li>
<li>floating-point assist (e.g., when an instruction operates with denormal floating-point value)</li>
</ul>
</li>
<li><strong>Instruction Decoded Queue (IDQ)</strong>
<ul>
<li>provides the interface between the in-order front-end and the out-of-order backend.</li>
<li>IDQ queues up the UOPs in order. The IDQ has a total of 128 UOPs</li>
</ul>
</li>
</ul>
<h3 id="cpu-back-end">CPU Back-End</h3>
<p>The CPU Back-End employs an Out-Of-Order engine that executes instructions and stores results.</p>
<ul>
<li><strong>ReOrder buffer (ROB)</strong>, 224 entry(skylake)
<ul>
<li>maps the architecture-visible registers to the physical registers used in the scheduler/reservation station unit.</li>
<li>provides register renaming and tracks speculative execution.</li>
<li>ROB entries are always retired in program order.</li>
</ul>
</li>
<li><strong>Reservation Station/Scheduler (RS)</strong>
<ul>
<li>tracks the availability of all resources for a given UOP and dispatches the UOP to the assigned port once it is ready.</li>
<li>The core is 8-way superscalar. Thus the RS can dispatch up to 8 UOPs per cycle.</li>
</ul>
</li>
</ul>
<p>Execution ports:</p>
<ul>
<li><strong>Ports 0/1/5/6</strong> provide all the integer, FP, and vector ALU. UOPs dispatched to those ports do not require memory operations.</li>
<li><strong>Port 0/1</strong> - Simple move, arithmetic and logic operations can go to either port 0 or 1, whichever is vacant first.</li>
<li><strong>Port 0</strong> also handles multiplication, division, integer shifts and rotates, and floating point operations.</li>
<li><strong>Port 1</strong> also handles jumps and some MMX and XMM operations.</li>
<li><strong>Port 2</strong> handles all reads from memory and a few string and XMM operations,</li>
<li><strong>port 3</strong> store address unit (calculates addresses for memory write)</li>
<li><strong>port 4</strong> executes all memory write operations.</li>
<li><strong>Port 7</strong> is used for address generation.</li>
</ul>
<p>Memory write operations require two μops, one for port 3 and one for port 4
Memory read operations use only one μop (port 2).</p>
<h2 id="the-pipeline-in-pm">The pipeline in PM</h2>
<p>The PM builds on the same basic microarchitecture as PPro, P2 and P3, while the
P4/NetBurst design has been discontinued.</p>
<br>
<h1 id="cpu-execution-optimization">CPU execution optimization</h1>
<p>(Agner manual - chapter 9 Optimizing for speed)</p>
<h2 id="cpu-execution">CPU execution</h2>
<p>To maximize ILP (Instruction Level Parallelism):</p>
<ul>
<li>Superscalar: Most modern CPUs are superscalar i.e., they can issue more than one instruction in a given cycle. Issue-width is the maximum number of instructions that can be issued during the same cycle. Typical issue-width of current generation CPUs ranges from 2-6.</li>
<li>Mulitple execution unit</li>
<li>deep pipeline</li>
<li>out-of-order execution</li>
<li>speculative execution</li>
</ul>
<h3 id="order-of-order-execution">Order of order execution</h3>
<p>CPU has the ability to detect whether an instruction depends on the output of a previous instruction.</p>
<p>OOO execution CPUs must still give the same result as if all instructions were executed in the program order, ie., CPUs must retire all instructions in the program order, i.e., the instructions complete the WB stage in the program order. An instruction is called <em>retired</em> when it is finally executed, and its results are correct and visible in the architectural state.</p>
<h3 id="pipeline-hazards">Pipeline hazards</h3>
<p>Pipeline hazards prevent the ideal pipeline behavior resulting in stalls. The three classes of hazards are structural hazards (resource conflicts), data hazards (described below), and control hazards (caused by branches and other instructions that change the program flow).</p>
<ul>
<li>Read-after-write (RAW) hazard requires dependent read to execute after write. CPUs implement data forwarding from a later stage of the pipeline to an earlier stage (called <em>“bypassing”</em>) to mitigate the penalty associated with the RAW hazard.</li>
<li>Write-after-read (WAR) hazard requires dependent write to execute after read. WAR hazard is not a true dependency and can be eliminated by <em>register renaming</em></li>
</ul>
<pre><code>R1 = R0 ADD 1
R0 = R2 ADD 2 # rename all the occurrences of R0 register starting from the write operation and below (to eliminate WAR)
</code></pre>
<ul>
<li>Write-after-write (WAW) hazard requires dependent write to execute after write. WAW hazards are also eliminated by <em>register renaming</em></li>
</ul>
<h3 id="register-rename">Register rename</h3>
<ul>
<li>The use of different physical registers for the same logical register enables the CPU to make the last three instructions in example 9.1b independent of the first three instructions.</li>
<li>This is what the CPU does for us. The CPU, when translating instructions to micro-operations (micro-ops) which the Out-of-order algorithm will execute, renames the registers internally to eliminate these dependencies, so the micro-ops deal with renamed, internal registers, rather than with the logical ones as we know them.</li>
<li>you can generally assume that the number of physical registers is sufficient for quite a lot of instruction reordering</li>
<li>All general purpose registers, stack pointer, flags, floating point registers, vector registers, and possibly segment registers can be renamed. Many processors do not allow the control words, and the floating point status word to be renamed, and this is the reason why code that modifies these registers is slow.</li>
</ul>
<h3 id="partial-register">Partial register</h3>
<ul>
<li>Some CPUs from both Intel, AMD and VIA are unable to rename a partial register.</li>
<li>The problems are avoided by replacing mov ax,[mem3] with movzx eax,[mem3]. This resets the high bits of eax and breaks the dependence on any previous value of eax.</li>
<li>In 64-bit mode, it is sufficient to write to the 32-bit register because this always resets the upper part of a 64-bit register. Thus, movzx eax,[mem3] and mov rax,[mem3] are doing exactly the same thing.</li>
<li>The INC and DEC instructions are inefficient on some CPUs because they write to only part of the flags register (excluding the carry flag). Use ADD or SUB instead to avoid false dependencies or inefficient splitting of the flags register, especially if they are followed by an instruction that reads the flags.</li>
</ul>
<h2 id="micro-operations---uops">Micro-operations - uops</h2>
<p>The CPU are translating all instructions into microoperations - abbreviated μops or uops</p>
<ul>
<li>The advantage of this is that the <strong>μops can be executed out of order</strong>.
<ul>
<li>Eg. <code>ADD EAX,[MEM2]</code> instruction is split into two μops. The advantage of this is that
the microprocessor can fetch the value of [MEM2] at the same time as it is doing other things</li>
</ul>
</li>
<li>The splitting into μops also makes the stack work more efficiently
<ul>
<li>Eg. <code>push eax; call func</code></li>
<li>The <code>PUSH EAX</code> instruction may be split into two μops which can be represented as <code>SUB ESP,4</code> and <code>MOV [ESP],EAX</code>.</li>
<li><code>SUB ESP,4</code> μop can be executed even if the value of EAX is not ready yet.</li>
<li>The <code>CALL</code> operation needs the new value of ESP, so the <code>CALL</code> don’t have to wait for the value of EAX</li>
<li>Thanks to the use of μops, the value of the stack pointer almost never causes delays in normal programs.</li>
</ul>
</li>
</ul>
<h3 id="macro-op-fusion">macro-op fusion</h3>
<p>On the opposite, Uops can also be fused. There are two types of fusion:</p>
<ul>
<li><em>Microfusion</em> - fuse uops from the same machine instruction. Microfusion can only be applied to two types of combinations: memory write operations and read-modify operations.</li>
</ul>
<pre><code># Read the memory location [ESI] and add it to EAX
# Two uops are fused into one at the decoding step.
add eax, [esi]
</code></pre>
<ul>
<li><em>Macrofusion</em> - fuse uops from different machine instructions. The decoders can fuse arithmetic or logic
instruction with a subsequent conditional jump instruction into a single compute-and-branch μop in certain
cases. For example:</li>
</ul>
<pre><code># Two uops from DEC and JNZ instructions are fused into one
.loop:
dec rdi
jnz .loop
</code></pre>
<p>uops fusion saves bandwidth in all stages of the pipeline from decoding to retirement.</p>
<ul>
<li>share a single entry in the reorder buffer (ROB).</li>
<li>This single ROB entry represents two operations that have to be done by two different execution unites (The fused ROB entry is dispatched to two different execution ports)</li>
<li>retired as a single unit</li>
</ul>
<h2 id="instruction-fetch">Instruction fetch</h2>
<ul>
<li>Many processors cannot fetch more than 16 bytes of instruction code per clock cycle. It may be necessary to make instructions as short as possible if this limit turns out to be critical.
<ul>
<li>One way to make it shorter is to replace memory operands by pointers. The address of memory operands can possibly be loaded into pointer registers</li>
</ul>
</li>
<li>Instruction fetching is delayed by jumps on most processors.
<ul>
<li>Branches that are not taken and correctly predicted do not delay instruction fetching.</li>
<li>It is therefore advantageous to organize the commonly taken branch to be the one where the conditional jump is not taken.</li>
</ul>
</li>
<li>Most processors fetch instructions in aligned 16-byte or 32-byte blocks.
<ul>
<li>It can be advantageous to align critical loop entries and subroutine entries by 16.</li>
</ul>
</li>
<li>Instruction decoding is often a bottleneck.
<ul>
<li>Instructions with multiple prefixes can slow down decoding.</li>
<li>Avoid address size prefixes.</li>
<li>Avoid operand size prefixes on instructions with an immediate operand. For example, it is preferred to replace MOV AX,2 by MOV EAX,2.</li>
</ul>
</li>
<li>Some CPUs have a μop cache or a tiny loopback buffer that helps remove the bottleneck of instruction decoding in small loops.
<ul>
<li>Keep loops small so that they are likely to fit into the μop cache or loopback buffer.</li>
<li>Avoid unnecessary loop unrolling.</li>
</ul>
</li>
</ul>
<h2 id="speculative-execution">Speculative execution</h2>
<ul>
<li>Modern CPU contains many stages, instruction fetch, decoding, register allocation and renaming, μop reordering, execution, and retirement. The biggest problem with pipelining is branches in the code.</li>
<li>Speculative execution means that the instructions are decoded and executed, but the results are <em>not</em> retired into the permanent register file, and memory writes are pending (held in <em>reorder buffer (ROB)</em> or called <em>CPU write buffer</em>) until the branch instruction is finally resolved.</li>
<li>In case of <strong>branch misprediction</strong>, the pipeline is flushed, the results of the speculative execution are discarded and the other branch is fed into the pipeline. The number of wasted clock cycles is approximately equal to the length of the pipeline.</li>
</ul>
<p>Speculative execution can execute invalid instruction that normally could result in crash, e.g., the processor really does dereference a NULL pointer (like in below code) or read the non-existing vector element <code>v[i+1]</code>  (towards the end of loop) during the speculative execution, then pretends that it never happened. The catastrophic response to such a potential disaster must be held pending, neither discarded nor allowed to become a reality until the branch condition is actually evaluated. One particular case is memory writes must be held until branch evaluation (this is done via <em>CPU write buffer</em>).</p>
<pre><code class="language-C++"><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">f</span><span class="hljs-params">(<span class="hljs-type">int</span>* p)</span> </span>{
    <span class="hljs-keyword">if</span> (p) {
        <span class="hljs-keyword">return</span> *p;
    } <span class="hljs-keyword">else</span> {
        <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;
    }
}
</code></pre>
<p>Speculative execution, together with caching effect, this is the source of <a href="spectre.html">spectre attack</a></p>
<h2 id="branch-predication">Branch predication</h2>
<p>The prediction has two aspects:</p>
<ul>
<li>predicting whether a conditional jump will be taken or not</li>
<li>predicting the target address that a conditional or unconditional jump goes to.</li>
</ul>
<p>A cache called <strong>Branch Target Buffer</strong> (BTB) stores the target address of all jumps.</p>
<p>With <code>perf stat</code>, you can see the <em>branch-misses</em> stats, even 1% is pretty bad in practice.</p>
<h2 id="optimize-jump-and-call">Optimize jump and call</h2>
<ul>
<li>It is good to place more frequent taken branch first (right after conditional jump)</li>
<li>Tail calls: It is possible to replace a call followed by a return by a jump</li>
<li>It is often possible to eliminate an unconditional jump by copying the code that it jumps to.</li>
<li>Replacing conditional jumps with conditional moves, unless
We can say that a conditional jump is faster than a conditional move if the code is part of a dependency chain and the prediction rate is better than 75%.</li>
<li>A conditional jump is also preferred if we can avoid a lengthy calculation of d or e when the other operand is chosen.</li>
<li>Loop-carried dependency chains are particularly sensitive to the disadvantages of conditional moves. because the dependency chain is broken every time a correct branch prediction is made.</li>
<li>Replacing conditional jumps with conditional set instructions, if a conditional jump is used for setting a Boolean variable to 0 or 1
<ul>
<li>SETcc</li>
</ul>
</li>
</ul>

        
        
    </body>
    </html>